{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3ZCzV6SuDNPes64rrkRx2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denisganga/the_plant_doctor/blob/main/The_plant_doctor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "U-n5AmNC1tR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f41ed0-b4ee-45f0-aa90-fef91c770f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#importing the required modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import random_split\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "ax5pfN_yLI7I"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzipping my dataset\n",
        "import zipfile\n",
        "\n",
        "zip_file_path =  \"/content/drive/My Drive/the_plant_doctor/archive.zip\"\n",
        "extract_path = \"/content/dataset\"\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "5vHRM7_t1brl"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data directory (the path where your unzipped dataset is located)\n",
        "data_dir=\"/content/dataset\""
      ],
      "metadata": {
        "id": "DaLpY3ptLv5m"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setup device agnostic code(using the GPU if available)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "0oSWPrwh8g8o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6d45688-0f7a-4a5e-d484-4e851c1af75c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the transformations\n",
        "data_transforms =transforms.Compose([\n",
        "    #make the model more robust to differently oriented images.\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "\n",
        "    #random cropping of images to create multiple views of the same image\n",
        "    transforms.RandomCrop(size=(224,224), padding=10),\n",
        "\n",
        "    #Apply random color transformations to the images to make the model more invariant to changes in lighting and color\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2,hue=0.2),\n",
        "\n",
        "    #help the model focus on important features and reduce noise\n",
        "    transforms.GaussianBlur(kernel_size=3),\n",
        "\n",
        "    #resize and crop the image to create variations in the field of view.\n",
        "    transforms.RandomResizedCrop(size=(224,224), scale=(0.8, 1.0)),\n",
        "\n",
        "    #introduce controlled occlusions or \"erasing\" of parts of the image during training\n",
        "    transforms.RandomErasing(),\n",
        "\n",
        "    #Randomly flip the image horizontally\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "\n",
        "    #Convert the image to a PyTorch tensor\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "     # Normalize the image based on typical RGB mean and standard deviation\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "wLb8OHb77iVN"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dataset using ImageFolder\n",
        "dataset= datasets.ImageFolder(data_dir, transform=data_transforms)"
      ],
      "metadata": {
        "id": "vb3gkgEjIwEo"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class labels based on the dataset structure\n",
        "classes = dataset.classes"
      ],
      "metadata": {
        "id": "m1ioGFcjNpvu"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset into training and testing sets\n",
        "train_size = int(0.8*len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset,[train_size, test_size])"
      ],
      "metadata": {
        "id": "2vJkMe3VONnB"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZlllHyzQMvw",
        "outputId": "162e3f43-6595-4b2a-e5d4-5bfeee00ccbe"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41276\n",
            "33020\n",
            "8256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a Dataloader for efficient dataloading and batch\n",
        "batch_size = 7\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "num_samples = len(dataset)"
      ],
      "metadata": {
        "id": "RwPjdE7XQx-9"
      },
      "execution_count": 94,
      "outputs": []
    }
  ]
}